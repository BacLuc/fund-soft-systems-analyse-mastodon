{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of Software Systems - SE Part I Assignment\n",
    "\n",
    "By Andy Wiemeyer and Lucius Bachmann"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup tools\n",
    "* checkout repo\n",
    "* initialize Git utility\n",
    "* You can recreate the Repository object with other parameters to analyze different time periods.\n",
    "  The last year was used that the setup is fast."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from datetime import datetime\n",
    "from pydriller import Repository, Git\n",
    "from os import path, mkdir\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "repo_remote_path = 'https://github.com/mastodon/mastodon.git'\n",
    "repo_path = 'mastodon'\n",
    "repo_checkout_path = f'{repo_path}/{repo_path}'\n",
    "filepath = 'app'\n",
    "\n",
    "since = datetime.fromisoformat('2021-11-08')\n",
    "to = datetime.fromisoformat('2022-11-08')\n",
    "\n",
    "if not path.exists(repo_path):\n",
    "    mkdir(repo_path)\n",
    "\n",
    "repo = Repository(repo_remote_path, clone_repo_to=repo_path, since=since, to=to, filepath=filepath)\n",
    "# clone repo if necessary\n",
    "for commit in repo.traverse_commits():\n",
    "    break\n",
    "git = Git(repo_checkout_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkout repo at tag v3.5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = git.get_commit_from_tag('v3.5.3')\n",
    "git.checkout(tag.hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1 Complexity Hotspots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. You must consider only the app folder from the Mastodon repository\n",
    "(i.e., https://github.com/mastodon/mastodon)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-> nothing to do"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Decide on the granularity of your analysis of software entities (e.g., source code\n",
    "files); describe why you selected this specific granularity.\n",
    "\n",
    "We decided to look at single files TODO: motivation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Create a list of all these entities, as they appear in the latest stable release of\n",
    "Mastodon (i.e., tag v3.5.3)."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_file_paths_all_dirs = git.files() #full path of all files in the analyzed commit\n",
    "subdirectory_start = \"/\" + repo_checkout_path + \"/\"\n",
    "full_file_paths = [path for path in full_file_paths_all_dirs if subdirectory_start+\"app/\" in path]\n",
    "subdirectory_start_index = full_file_paths[0].find(subdirectory_start) + len(subdirectory_start)\n",
    "subdirectory_prefix = full_file_paths[0][:subdirectory_start_index]#used later\n",
    "file_paths = [path[subdirectory_start_index:] for path in full_file_paths] #paths relative to analyzed subdirectory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_names = [path[max(0,path.rfind(\"/\"))+1:] for path in full_file_paths]\n",
    "print(f\"Amount of different files with equal name: {len(file_names)-len(set(file_names))}\")\n",
    "counted_file_names = {}\n",
    "for name in file_names:\n",
    "    if name not in counted_file_names:\n",
    "        counted_file_names[name] = 1\n",
    "    else:\n",
    "        counted_file_names[name] += 1\n",
    "print([f\"{name}: {count}\" for name, count in counted_file_names.items() if count>1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A lot of different files have the same name (see above) so we use the paths to identify files:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(file_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Decide on the type of complexity you want to measure for your software entities\n",
    "and explain why you selected this type.\n",
    "\n",
    "We decided at to look at the lines of code in a file TODO: explain"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Decide on a timeframe on which you want to base your analysis and explain the\n",
    "rationale of your choice.\n",
    "\n",
    "TODO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. For each entity in the system, measure its complexity and the number of changes\n",
    "(in the given timeframe). Merge these two pieces of information together to cre-\n",
    "ate a candidate list of problematic hotspots in the app part of Mastodon."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_to_results = './analysis_data.csv'\n",
    "if not os.path.isfile(path_to_results): #check if we have already saved the results\n",
    "    analysis_df = pd.DataFrame( #create dataframe with\n",
    "        {'Name':file_names, 'Full Path':full_file_paths}, #data columns\n",
    "        index=file_paths) #and index\n",
    "\n",
    "    #Compute complexities\n",
    "    complexity_comp_exceptions = {} #to analyse what caused error (mostly images)\n",
    "    for idx in analysis_df.index:\n",
    "        try:\n",
    "            with open(analysis_df.loc[idx, 'Full Path'], 'r') as file:\n",
    "                analysis_df.loc[idx, 'Complexity'] = len(file.readlines())\n",
    "        except Exception as e:\n",
    "            complexity_comp_exceptions[idx]=e\n",
    "    analysis_df.to_csv(path_to_results)\n",
    "\n",
    "    # Count amount of times changed\n",
    "    analysis_df['CommitPath'] = analysis_df.index #For tracking the path that a file has in the current commit if it was moved\n",
    "    analysis_df['Amount of changes'] = 0 #set change counter to 0\n",
    "    for commit in reversed(list(repo.traverse_commits())):\n",
    "        for file in commit.modified_files:\n",
    "            idx = analysis_df[analysis_df['CommitPath']==file.new_path].index\n",
    "            analysis_df.loc[idx, 'Amount of changes'] += 1\n",
    "            analysis_df.loc[idx, 'CommitPath'] = file.old_path #update commit path\n",
    "    analysis_df.drop(columns='CommitPath', inplace=True) #get rid of temporary indexing\n",
    "    analysis_df.to_csv(path_to_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% compute results\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "analysis_df = pd.read_csv(path_to_results, index_col=[0])\n",
    "# show results\n",
    "#analysis_df['Complexity'].sort_values(ascending=False)[:10] #Print top 10 entries\n",
    "#analysis_df['Amount of changes'].sort_values(ascending=False)[:10] #Print top 10 entries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% load results\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "7. Visualize the hotspots with a visualization of your choice."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "complexity_hist = px.histogram(analysis_df, x='Complexity', hover_data={\"path\": analysis_df.index})\n",
    "complexity_hist.show() #exponential dist in complexity -> use log axis\n",
    "change_amount_hist = px.histogram(analysis_df, x='Amount of changes', hover_data={\"path\": analysis_df.index})\n",
    "change_amount_hist.show() #exponential dist in amount of changes -> use log axis\n",
    "\n",
    "comparison_scatter = px.scatter(analysis_df, x='Complexity', y='Amount of changes',\n",
    "                 hover_data={\"path\": analysis_df.index})\n",
    "comparison_scatter.show()\n",
    "\n",
    "comparison_scatter_log = px.scatter(analysis_df, x='Complexity', y='Amount of changes',\n",
    "                 log_x=True, log_y=True,\n",
    "                 hover_data={\"path\": analysis_df.index})\n",
    "comparison_scatter_log.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "8. Analyze six candidate hotspots (not necessarily the top ones) through:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "computes the complextity trends for a list of file paths\n",
    "return: dictionary with paths as key and a list containing a complexity measurements from oldest to newest commit as value\n",
    "\"\"\"\n",
    "def compute_complexity_trends(file_paths):\n",
    "    complexity_trends = {path: [] for path in file_paths}\n",
    "    commit_paths = {path:path for path in file_paths} #For tracking the path that a file has in the current commit if it was moved\n",
    "\n",
    "    for commit in reversed(list(repo.traverse_commits())):#TODO: use whole list\n",
    "        git.checkout(commit.hash)\n",
    "\n",
    "        #add trend values for current commit\n",
    "        for key_path, value_path in commit_paths.items():\n",
    "            try:\n",
    "                full_path = subdirectory_prefix+value_path\n",
    "                with open(full_path, 'r') as file:\n",
    "                    complexity_trends[key_path].insert(0,len(file.readlines()))\n",
    "            except Exception as e:\n",
    "                print(\"Issue with complexity trend computation: \", e)\n",
    "\n",
    "        #update commit paths\n",
    "        for file in commit.modified_files:\n",
    "            for key_path, value_path in commit_paths.items():\n",
    "                if value_path==file.new_path:\n",
    "                    commit_paths[key_path]=file.old_path\n",
    "\n",
    "    git.checkout(tag.hash) #return to initial checkout\n",
    "    return complexity_trends"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hotspot_candidates = [\n",
    "    'app/models/status.rb', #Very high change rate somewhat high complexity\n",
    "    'app/lib/feed_manager.rb',\n",
    "    'app/services/activitypub/process_status_update_service.rb',\n",
    "    'app/javascript/mastodon/actions/compose.js',\n",
    "    'app/helpers/application_helper.rb',\n",
    "    'app/lib/activitypub/activity/create.rb',\n",
    "    'app/views/notification_mailer/_status.text.erb',\n",
    "\n",
    "    'app/javascript/fonts/roboto/roboto-medium-webfont.svg', #Complexity outlier, never changes\n",
    "    'app/javascript/styles/mastodon/components.scss', #Very high complexity, very high amount of changes\n",
    "    'app/javascript/mastodon/locales/defaultMessages.json', #High change rate, very high complexity\n",
    "    ]\n",
    "complexity_trends = compute_complexity_trends(hotspot_candidates)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Compute trends and add to dataframe\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_complexity_trend(index):\n",
    "    label, complexity_list = list(complexity_trends.items())[index]\n",
    "    commits_num = list(range(len(complexity_list)))\n",
    "    complexity_trend_line = px.line(x=commits_behind, y=complexity_list, title=f\"Complexity trend for {label}\",\n",
    "                                    labels={'x': 'number of commits', 'y': 'complexity [LOC]'})\n",
    "    complexity_trend_line.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Visualize trends\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Candidate 1:\n",
    "...manual analysis...."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_complexity_trend(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Candidate 2:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_complexity_trend(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Candidate 3:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_complexity_trend(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Candidate 4:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_complexity_trend(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Candidate 5:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_complexity_trend(4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Candidate 6:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_complexity_trend(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2 Temporal/Logical Coupling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Determine what could be cases of temporal/logical coupling and generate a list\n",
    "of candidates with a set of coupled entities."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Visualize these candidate sets of couple entities with a visualization of your\n",
    "choice."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. For three set candidates in the list:\n",
    "• analyze and explain why these entities are coupled;\n",
    "• describe how important it would be to fix them, and any ideas for their\n",
    "improvement."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Canditate set 1:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Canditate set 2:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Candidate set 3:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3 Defective Hotspots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Decide on how you want to detect entities that had defects in the past (e.g.,\n",
    "commit message analysis vs. issue tracking system analysis) and motivate your\n",
    "choice."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Determine defective hotspots among the entities in the timeframe that you pre-\n",
    "viously selected (i.e., consider only defects in the selected timeframe). What\n",
    "conclusions can you draw from this?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Determine complexity hotspots at the beginning of your timeframe, then corre-\n",
    "late them with the defects they have presented throughout the entire timeframe.\n",
    "Is there a correlation? Why do you think this is the case?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. What conclusions can you draw from the relationship between defective hotspots\n",
    "and complexity hotspots in Mastodon? And on these two metrics in general?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}